{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/ssd001/home/ama/workspace/ama-at-vector/best-mix\n"
     ]
    }
   ],
   "source": [
    "cd '/h/ama/workspace/ama-at-vector/best-mix'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "from mixup import mixup_graph\n",
    "import time\n",
    "from utils_wip import gradmix_v2, gradmix_v2_improved_v2\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import OrderedDict\n",
    "args = {'dataset': 'cifar10', 'data_dir': '/h/ama/workspace/ama-at-vector/best-mix/data', 'root_dir': '/scratch/hdd001/home/ama/mixup/2022-07-02/11', 'labels_per_class': 5000, 'valid_labels_per_class': 0, 'arch': 'preactresnet18', 'initial_channels': 64, 'epochs': 300, 'method': 'vanilla', 'train': 'vanilla', 'in_batch': False, 'mixup_alpha': 1.0, 'dropout': False, 'box': False, 'graph': False, 'neigh_size': 4, 'n_labels': 3, 'beta': 1.2, 'gamma': 0.5, 'eta': 0.2, 'transport': True, 't_eps': 0.8, 't_size': -1, 'adv_eps': 10.0, 'adv_p': 0.0, 'clean_lam': 0.0, 'mp': 8, 'batch_size': 100, 'learning_rate': 0.2, 'momentum': 0.9, 'decay': 0.0001, 'schedule': [100, 200], 'gammas': [0.1, 0.1], 'print_freq': 100, 'resume': '', 'start_epoch': 0, 'evaluate': False, 'ngpu': 1, 'workers': 2, 'seed': 1, 'add_name': '', 'log_off': False, 'job_id': 7889109, 'enable_wandb': False, 'wandb_project': 'test', 'job_name': '11', 'blur_sigma': 1.0, 'kernel_size': 5, 'grad_normalization': 'L1', 'eval_mode': False, 'new_implementation': True, 'with_shift': True, 'use_yp_argmax': False, 'mix_stride': 2, 'rand_pos': 1, 'prob_mix': 1.0, 'mix_schedule': 'fixed', 'mix_scheduled_epoch': 50, 'upper_lambda': 0.5, 'mixup_alpha2': 0.0, 'use_cuda': True}\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': 'cifar10', 'data_dir': '/h/ama/workspace/ama-at-vector/best-mix/data', 'root_dir': '/scratch/hdd001/home/ama/mixup/2022-07-02/11', 'labels_per_class': 5000, 'valid_labels_per_class': 0, 'arch': 'preactresnet18', 'initial_channels': 64, 'epochs': 300, 'method': 'vanilla', 'train': 'vanilla', 'in_batch': False, 'mixup_alpha': 1.0, 'dropout': False, 'box': False, 'graph': False, 'neigh_size': 4, 'n_labels': 3, 'beta': 1.2, 'gamma': 0.5, 'eta': 0.2, 'transport': True, 't_eps': 0.8, 't_size': -1, 'adv_eps': 10.0, 'adv_p': 0.0, 'clean_lam': 0.0, 'mp': 8, 'batch_size': 100, 'learning_rate': 0.2, 'momentum': 0.9, 'decay': 0.0001, 'schedule': [100, 200], 'gammas': [0.1, 0.1], 'print_freq': 100, 'resume': '', 'start_epoch': 0, 'evaluate': False, 'ngpu': 1, 'workers': 2, 'seed': 1, 'add_name': '', 'log_off': False, 'job_id': 7889109, 'enable_wandb': False, 'wandb_project': 'test', 'job_name': '11', 'blur_sigma': 1.0, 'kernel_size': 5, 'grad_normalization': 'L1', 'eval_mode': False, 'new_implementation': True, 'with_shift': True, 'use_yp_argmax': False, 'mix_stride': 2, 'rand_pos': 1, 'prob_mix': 1.0, 'mix_schedule': 'fixed', 'mix_scheduled_epoch': 50, 'upper_lambda': 0.5, 'mixup_alpha2': 0.0, 'use_cuda': True}\n"
     ]
    }
   ],
   "source": [
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.eval_mode = False\n",
    "args.dataset='cifar10'\n",
    "args.num_classes=10\n",
    "args.blur_sigma=2\n",
    "args.lr=0.1\n",
    "log = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "''' Model '''\n",
    "import models\n",
    "# import torchvision.models as models\n",
    "from load_data import load_data_subset\n",
    "from collections import OrderedDict\n",
    "\n",
    "labels_per_class = 5000\n",
    "\n",
    "batch_size = 100\n",
    "workers=2\n",
    "dataset='cifar10'\n",
    "data_dir='data'\n",
    "valid_labels_per_class=0\n",
    "mixup_alpha=0\n",
    "train_loader, valid_loader, _, test_loader, num_classes = load_data_subset(batch_size,workers,dataset,data_dir,labels_per_class=labels_per_class,valid_labels_per_class=valid_labels_per_class,mixup_alpha=mixup_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "# Codes are borrowed from https://github.com/vikasverma1077/manifold_mixup/tree/master/supervised\n",
    "\n",
    "import os, sys, shutil, time, random\n",
    "from collections import OrderedDict\n",
    "\n",
    "sys.path.append('..')\n",
    "if sys.version_info[0] < 3:\n",
    "    import cPickle as pickle\n",
    "else:\n",
    "    import _pickle as pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from load_data import load_data_subset\n",
    "from logger import plotting, copy_script_to_folder, AverageMeter, RecorderMeter, time_string, convert_secs2time\n",
    "import models\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import ipdb\n",
    "from utils_log import wandbLogger, saveCheckpoint\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from utils_wip import gradmix, reweighted_lam, gradmix_v2, gradmix_v2_improved, gradmix_v2_improved_v2\n",
    "from mixup import to_one_hot, get_lambda\n",
    "\n",
    "\n",
    "def train(train_loader, model, optimizer, epoch, args, log, mp=None):\n",
    "    '''train given model and dataloader'''\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    mixing_avg = []\n",
    "    prob_mix = get_prob_mix(args.mix_schedule, args.prob_mix, epoch, args.mix_scheduled_epoch)\n",
    "\n",
    "    if args.method == 'ours' and args.blur_sigma != 100:\n",
    "        blurrer = transforms.GaussianBlur(kernel_size=(args.kernel_size, args.kernel_size),\n",
    "                                          sigma=(args.blur_sigma, args.blur_sigma))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input = input.cuda()\n",
    "        target = target.long().cuda()\n",
    "\n",
    "        unary = None\n",
    "        noise = None\n",
    "        adv_mask1 = 0\n",
    "        adv_mask2 = 0\n",
    "\n",
    "        # train with clean images\n",
    "        if args.train == 'vanilla':\n",
    "            input_var, target_var = Variable(input), Variable(target)\n",
    "            output, reweighted_target = model(input_var, target_var)\n",
    "#             loss = bce_loss(softmax(output), reweighted_target)\n",
    "            loss = torch.nn.CrossEntropyLoss()(softmax(output),target_var)\n",
    "            print(loss)\n",
    "    \n",
    "            if loss>10:\n",
    "                ipdb.set_trace()\n",
    "\n",
    "        # integrating our method :AVery\n",
    "        elif args.train == 'ours':\n",
    "\n",
    "            batch_size = input.shape[0]\n",
    "            mix_size = int(batch_size*prob_mix)\n",
    "\n",
    "            # if mix_size is 0, we are simply doing standard training with no DA\n",
    "            if mix_size == 0:\n",
    "                input_var, target_var = Variable(input), Variable(target)\n",
    "                output, reweighted_target = model(input_var, target_var)\n",
    "\n",
    "                loss = bce_loss(softmax(output), reweighted_target)\n",
    "            else:\n",
    "                if mix_size == batch_size:\n",
    "                    # entire batch is DA\n",
    "                    input_2b_mixed = input\n",
    "                    target_2b_mixed = target\n",
    "                    input_std = None\n",
    "                    target_std = None\n",
    "                else:\n",
    "                    # some inputs are augmented, some are not\n",
    "                    input_std, input_2b_mixed = input[:(batch_size-mix_size)], input[(batch_size-mix_size):]\n",
    "                    target_std, target_2b_mixed = target[:(batch_size-mix_size)], target[(batch_size-mix_size):]\n",
    "\n",
    "                input_2b_mixed_var = Variable(input_2b_mixed, requires_grad=True)\n",
    "                target_2b_mixed_var = Variable(target_2b_mixed)\n",
    "\n",
    "                # calculate saliency\n",
    "                if args.eval_mode:\n",
    "                    model.eval()\n",
    "                else:\n",
    "                    model.train()\n",
    "                output = model(input_2b_mixed_var)\n",
    "\n",
    "                if args.use_yp_argmax:\n",
    "                    loss_batch = criterion_batch(output, output.argmax(dim=1))\n",
    "                else:\n",
    "                    loss_batch = criterion_batch(output, target_2b_mixed_var)\n",
    "                    \n",
    "#                 ipdb.set_trace()\n",
    "\n",
    "                loss_batch_mean = args.ratio*torch.mean(loss_batch, dim=0)\n",
    "                loss_batch_mean.backward(retain_graph=True)\n",
    "\n",
    "                model.train()\n",
    "\n",
    "                g = input_2b_mixed_var.grad.data.abs().mean(dim=1, keepdim=True).detach()\n",
    "\n",
    "                if args.blur_sigma == 100:\n",
    "                    if args.dataset == 'tiny-imagenet-200':\n",
    "                        _blur_sigma = np.random.uniform(low=2.0, high=3.0)\n",
    "                    else:\n",
    "                        _blur_sigma = np.random.uniform(low=1.0, high=2.0)\n",
    "                    blurrer = transforms.GaussianBlur(kernel_size=(args.kernel_size, args.kernel_size),\n",
    "                                                      sigma=(_blur_sigma, _blur_sigma))\n",
    "                g_tilde = blurrer(g)\n",
    "\n",
    "                if args.mixup_alpha2 == 0.:\n",
    "                    if args.mixup_alpha == 0.:\n",
    "                        sampled_alpha = 0.5\n",
    "                    else:\n",
    "                        sampled_alpha = get_lambda(args.mixup_alpha)\n",
    "                    sampled_alpha *= args.upper_lambda\n",
    "                else:\n",
    "                    sampled_alpha = get_lambda(args.mixup_alpha, args.mixup_alpha2)\n",
    "#                 ipdb.set_trace()\n",
    "                mixed_x, mixed_y, mixed_lam = gradmix_v2_improved_v2(input_2b_mixed_var,\n",
    "                                                                 target_2b_mixed_var,\n",
    "                                                                 g_tilde,\n",
    "                                                                 alpha=sampled_alpha,\n",
    "                                                                 normalization=args.grad_normalization,\n",
    "                                                                 stride=args.mix_stride,\n",
    "                                                                 debug=False,\n",
    "                                                                 rand_pos=args.rand_pos)\n",
    "\n",
    "                ipdb.set_trace()\n",
    "#                 optimizer.zero_grad()\n",
    "\n",
    "                reweighted_target_mix = reweighted_lam(mixed_y, mixed_lam, args.num_classes)\n",
    "\n",
    "                output_mix = model(mixed_x)\n",
    "                loss = (1-args.ratio)*bce_loss(softmax(output_mix), reweighted_target_mix)\n",
    "                print(loss.item(), loss_batch_mean.item())\n",
    "                if loss.item()>1:\n",
    "                    ipdb.set_trace()\n",
    "\n",
    "        if args.train == 'ours':\n",
    "            if mix_size == 0:\n",
    "                prec1, prec5 = accuracy(output, target, topk=(1, 5))\n",
    "            elif mix_size == batch_size:\n",
    "                prec1, prec5 = accuracy(output_mix, target_2b_mixed, topk=(1, 5))\n",
    "            else:\n",
    "                if args.new_implementation:\n",
    "                    prec1, prec5 = accuracy(output_mix, target_concat, topk=(1, 5))\n",
    "                else:\n",
    "                    prec1_mix, prec5_mix = accuracy(output_mix, target_2b_mixed, topk=(1, 5))\n",
    "                    prec1_std, prec5_std = accuracy(output_std, target_std, topk=(1, 5))\n",
    "                    prec1 = prec1_mix + prec1_std\n",
    "                    prec5 = prec5_mix + prec5_std\n",
    "        elif args.train == 'vanilla':\n",
    "            prec1, prec5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec1.item(), input.size(0))\n",
    "        top5.update(prec5.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "    print_log(\n",
    "        '  **Train** Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}'.format(\n",
    "            top1=top1, top5=top5, error1=100 - top1.avg), log)\n",
    "    return top1.avg, top5.avg, losses.avg\n",
    "\n",
    "def get_prob_mix(mix_schedule, max_prob, epoch, scheduled_epoch):\n",
    "    \"\"\"\n",
    "    with scheldued mix,\n",
    "    if epoch < scheduled_epoch, we linearly increase the mix prob from 0 to max_prob\n",
    "    if epoch > scheduled_epoch, we fix the prob at max_prob\n",
    "    \"\"\"\n",
    "    if mix_schedule == 'fixed':\n",
    "        prob_mix = max_prob\n",
    "    elif mix_schedule == 'scheduled':\n",
    "        if epoch+1>=scheduled_epoch:\n",
    "            prob_mix = max_prob\n",
    "        else:\n",
    "            prob_mix = (epoch+1)/scheduled_epoch*max_prob\n",
    "    elif mix_schedule == 'delayed':\n",
    "        if epoch>=scheduled_epoch:\n",
    "            prob_mix = max_prob\n",
    "        else:\n",
    "            prob_mix = 0\n",
    "    return prob_mix\n",
    "\n",
    "bce_loss = nn.BCELoss().cuda()\n",
    "bce_loss_sum = nn.BCELoss(reduction='sum').cuda()\n",
    "softmax = nn.Softmax(dim=1).cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "criterion_batch = nn.CrossEntropyLoss(reduction='none').cuda()\n",
    "\n",
    "def accuracy(output, target, topk=(1, )):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "def print_log(print_string, log, end='\\n'):\n",
    "    '''print log'''\n",
    "    print(\"{}\".format(print_string), end=end)\n",
    "    if log is not None:\n",
    "        if end == '\\n':\n",
    "            log.write('{}\\n'.format(print_string))\n",
    "        else:\n",
    "            log.write('{} '.format(print_string))\n",
    "        log.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.__dict__['preactresnet18'](10, False, 1).cuda()\n",
    "\n",
    "# checkpoint = torch.load('checkpoint/cifar10_preact_ckpt_vanilla.pth.tar')\n",
    "\n",
    "# od = OrderedDict()\n",
    "# for key in checkpoint['state_dict'].keys():\n",
    "#     od[key[7:]] = checkpoint['state_dict'][key]\n",
    "# resnet.load_state_dict(od)\n",
    "\n",
    "# resnet = models.resnet18(pretrained=True)\n",
    "\n",
    "optimizer = torch.optim.SGD(resnet.parameters(),\n",
    "                                0.2,\n",
    "                                momentum=0.9,\n",
    "                                weight_decay=1e-3,\n",
    "                                nesterov=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2923, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2764, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2565, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2686, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-24:\n",
      "Traceback (most recent call last):\n",
      "  File \"/h/ama/.conda/envs/new-env/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/h/ama/.conda/envs/new-env/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/h/ama/.conda/envs/new-env/lib/python3.9/site-packages/torch/utils/data/_utils/pin_memory.py\", line 28, in _pin_memory_loop\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/h/ama/.conda/envs/new-env/lib/python3.9/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/h/ama/.conda/envs/new-env/lib/python3.9/site-packages/torch/multiprocessing/reductions.py\", line 289, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/h/ama/.conda/envs/new-env/lib/python3.9/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/h/ama/.conda/envs/new-env/lib/python3.9/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/h/ama/.conda/envs/new-env/lib/python3.9/multiprocessing/connection.py\", line 513, in Client\n",
      "    answer_challenge(c, authkey)\n",
      "  File \"/h/ama/.conda/envs/new-env/lib/python3.9/multiprocessing/connection.py\", line 757, in answer_challenge\n",
      "    message = connection.recv_bytes(256)         # reject large message\n",
      "  File \"/h/ama/.conda/envs/new-env/lib/python3.9/multiprocessing/connection.py\", line 221, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/h/ama/.conda/envs/new-env/lib/python3.9/multiprocessing/connection.py\", line 419, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/h/ama/.conda/envs/new-env/lib/python3.9/multiprocessing/connection.py\", line 388, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22129/1114504577.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtotal_time_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoc\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_22129/8085505.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, optimizer, epoch, args, log, mp)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'vanilla'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0minput_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreweighted_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;31m#             loss = bce_loss(softmax(output), reweighted_target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/new-env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/ssd001/home/ama/workspace/ama-at-vector/best-mix/models/preresnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, target, mixup, mixup_hidden, args, grad, noise, adv_mask1, adv_mask2, mp)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_reweighted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixup_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_reweighted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlayer_mix\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_reweighted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixup_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_reweighted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/new-env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/new-env/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/new-env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/ssd001/home/ama/workspace/ama-at-vector/best-mix/models/preresnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mshortcut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shortcut'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mshortcut\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/new-env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0mforward_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;31m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "args.ratio = 0.5\n",
    "args.method = 'vanilla'\n",
    "args.train = 'vanilla'\n",
    "\n",
    "total_time_list = []\n",
    "for i in range(1):\n",
    "    tic = time.perf_counter()\n",
    "    train(train_loader, resnet, optimizer, 0, args, log, mp=None)\n",
    "    toc = time.perf_counter()\n",
    "    total_time_list.append(toc-tic)\n",
    "\n",
    "total_time_list= np.array(total_time_list)\n",
    "print(f\"Average total time: {total_time_list.mean():0.4f} seconds (var: {total_time_list.var():0.4f})\")\n",
    "print(f\"Max/Min time: {total_time_list.max():0.4f}/{total_time_list.min():0.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-env",
   "language": "python",
   "name": "new-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
