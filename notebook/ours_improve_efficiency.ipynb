{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/ssd001/home/ama/workspace/ama-at-vector/best-mix\n"
     ]
    }
   ],
   "source": [
    "cd '/h/ama/workspace/ama-at-vector/best-mix'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "from mixup import mixup_graph\n",
    "import time\n",
    "import ipdb\n",
    "from utils_mixup import *\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_fig(input, target=None, title=None, save_dir=None):\n",
    "    fig, axes = plt.subplots(1,len(input),figsize=(3*len(input),3))\n",
    "    if title:\n",
    "        fig.suptitle(title, size=16)\n",
    "    if len(input) == 1 :\n",
    "        axes = [axes]\n",
    "        \n",
    "    for i, ax in enumerate(axes):\n",
    "        if len(input.shape) == 4:\n",
    "            ax.imshow(input[i].permute(1,2,0).numpy())\n",
    "        else :\n",
    "            ax.imshow(input[i].numpy(), cmap='gray', vmin=0., vmax=1.)\n",
    "        \n",
    "        if target is not None:\n",
    "            output = net((input[i].unsqueeze(0) - mean)/std)\n",
    "            loss = criterion(output, target[i:i+1])\n",
    "            ax.set_title(\"loss: {:.3f}\\n pred: {}\\n true : {}\".format(loss, CIFAR100_LABELS_LIST[output.max(1)[1][0]], CIFAR100_LABELS_LIST[target[i]]))\n",
    "        ax.axis('off')\n",
    "    plt.subplots_adjust(wspace = 0.1)\n",
    "    \n",
    "    if save_dir is not None:\n",
    "        plt.savefig(save_dir, bbox_inches = 'tight',  pad_inches = 0)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model, Data, Saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "''' Model '''\n",
    "import models\n",
    "# import torchvision.models as models\n",
    "from load_data import load_data_subset\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "resnet = models.__dict__['preactresnet18'](10, False, 1).cuda()\n",
    "\n",
    "# checkpoint = torch.load('/group-volume/Multimodal-Learning/ssl/vse_files/runs/fast_autoaugment/models/cifar10_preact_ckpt/vanilla.pth.tar')\n",
    "checkpoint = torch.load('checkpoint/cifar10_preact_ckpt_vanilla.pth.tar')\n",
    "\n",
    "od = OrderedDict()\n",
    "for key in checkpoint['state_dict'].keys():\n",
    "    od[key[7:]] = checkpoint['state_dict'][key]\n",
    "resnet.load_state_dict(od)\n",
    "\n",
    "# resnet = models.resnet18(pretrained=True)\n",
    "\n",
    "\n",
    "# resnet.load_state_dict(checkpoint['state_dict'])\n",
    "# mean = torch.tensor([x / 255 for x in [125.3, 123.0, 113.9]],dtype=torch.float32).reshape(1, 3, 1, 1).cuda()\n",
    "# std = torch.tensor([x / 255 for x in [63.0, 62.1, 66.7]], dtype=torch.float32).reshape(1, 3, 1, 1).cuda()\n",
    "labels_per_class = 5000\n",
    "mean = torch.tensor([125.3, 123.0, 113.9])/255\n",
    "std = torch.tensor([63.0, 62.1, 66.7])/255\n",
    "mean_torch = mean.unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "std_torch = std.unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "workers=2\n",
    "dataset='cifar10'\n",
    "# data_dir='/group-volume/Multimodal-Learning/ssl/vse_files/runs/fast_autoaugment/data'\n",
    "data_dir='data'\n",
    "valid_labels_per_class=0\n",
    "mixup_alpha=0\n",
    "train_loader, valid_loader, _, test_loader, num_classes = load_data_subset(batch_size,workers,dataset,data_dir,labels_per_class=labels_per_class,valid_labels_per_class=valid_labels_per_class,mixup_alpha=mixup_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Data '''\n",
    "\n",
    "sample_num=100\n",
    "for x,y in test_loader:\n",
    "    input_sp,targets = x[:sample_num,:],y[:sample_num]\n",
    "    break\n",
    "\n",
    "mean = torch.tensor([125.3, 123.0, 113.9])/255\n",
    "std = torch.tensor([63.0, 62.1, 66.7])/255\n",
    "mean_torch = mean.unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "std_torch = std.unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "# print_fig((input_sp * std_torch + mean_torch)[:sample_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Saliency '''\n",
    "resnet.cpu()\n",
    "resnet.eval()\n",
    "input_var = input_sp[:sample_num].clone().detach().requires_grad_(True)\n",
    "output = resnet(input_var)\n",
    "loss = criterion(output, targets[:sample_num])\n",
    "loss.backward()\n",
    "\n",
    "blurr = torchvision.transforms.GaussianBlur(5, sigma=(1.0, 1.0))\n",
    "grad = blurr(input_var.grad.detach().abs().mean(dim=1).squeeze())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average total time: 1.6374 seconds (var: 0.0010)\n",
      "Max/Min time: 1.6797/1.5856 seconds\n"
     ]
    }
   ],
   "source": [
    "total_time_list = []\n",
    "update_time_list = []\n",
    "update_counter_list = []\n",
    "for i in range(10):\n",
    "    tic = time.perf_counter()\n",
    "    mixed_x, mixed_y, mixed_lam= gradmix_v2_improved_v2(input_sp.cuda(), targets.cuda(), grad.unsqueeze(1).cuda(), \n",
    "                                                 alpha = 0.5, normalization = 'standard', debug=False, \n",
    "                                                 rand_pos = 1.0)\n",
    "\n",
    "\n",
    "    toc = time.perf_counter()\n",
    "    total_time_list.append(toc-tic)\n",
    "#     update_time_list.append(total_time_in_update)\n",
    "#     update_counter_list.append(update_counter)\n",
    "# update_time_list = np.array(update_time_list)\n",
    "total_time_list= np.array(total_time_list)\n",
    "# update_counter_list=np.array(update_counter_list)\n",
    "print(f\"Average total time: {total_time_list.mean():0.4f} seconds (var: {total_time_list.var():0.4f})\")\n",
    "# print(f\"Average time on update: {update_time_list.mean():0.4f} seconds (var: {update_time_list.var():0.4f})\")\n",
    "# print(f\"Average update: {update_counter_list.mean():0.4f} times\")\n",
    "print(f\"Max/Min time: {total_time_list.max():0.4f}/{total_time_list.min():0.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average total time: 1.1797 seconds (var: 0.0001)\n",
      "Max/Min time: 1.1929/1.1522 seconds\n"
     ]
    }
   ],
   "source": [
    "total_time_list = []\n",
    "update_time_list = []\n",
    "update_counter_list = []\n",
    "for i in range(10):\n",
    "    tic = time.perf_counter()\n",
    "    mixed_x, mixed_y, mixed_lam= gradmix_v2_improved_v2(input_sp.cuda(), targets.cuda(), grad.unsqueeze(1).cuda(), \n",
    "                                                 alpha = 0.5, normalization = 'standard', debug=False, \n",
    "                                                 rand_pos = 1.0)\n",
    "\n",
    "\n",
    "    toc = time.perf_counter()\n",
    "    total_time_list.append(toc-tic)\n",
    "#     update_time_list.append(total_time_in_update)\n",
    "#     update_counter_list.append(update_counter)\n",
    "# update_time_list = np.array(update_time_list)\n",
    "total_time_list= np.array(total_time_list)\n",
    "# update_counter_list=np.array(update_counter_list)\n",
    "print(f\"Average total time: {total_time_list.mean():0.4f} seconds (var: {total_time_list.var():0.4f})\")\n",
    "# print(f\"Average time on update: {update_time_list.mean():0.4f} seconds (var: {update_time_list.var():0.4f})\")\n",
    "# print(f\"Average update: {update_counter_list.mean():0.4f} times\")\n",
    "print(f\"Max/Min time: {total_time_list.max():0.4f}/{total_time_list.min():0.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0013532938901335\n",
      "1.133380592102185\n",
      "0.025799543131142855\n",
      "0.002167575992643833\n",
      "1.1396860950626433\n",
      "0.02575189806520939\n",
      "0.0019107030238956213\n",
      "1.1482399918604642\n",
      "0.0290583330206573\n",
      "0.0019217950757592916\n",
      "1.14610659587197\n",
      "0.029075664933770895\n",
      "0.0020501429680734873\n",
      "1.1517520709894598\n",
      "0.0255990088917315\n",
      "0.001981537090614438\n",
      "1.1505236078519374\n",
      "0.029007019940763712\n",
      "0.001925869146361947\n",
      "1.1541221339721233\n",
      "0.029035069048404694\n",
      "0.001936623128131032\n",
      "1.142139313975349\n",
      "0.028877269010990858\n",
      "0.0018495579715818167\n",
      "1.1444624809082597\n",
      "0.025669452967122197\n",
      "0.0010604490526020527\n",
      "1.1495408709160984\n",
      "0.029098871862515807\n",
      "Average total time: 1.1763 seconds (var: 0.0000)\n",
      "Max/Min time: 1.1857/1.1613 seconds\n"
     ]
    }
   ],
   "source": [
    "total_time_list = []\n",
    "update_time_list = []\n",
    "update_counter_list = []\n",
    "for i in range(10):\n",
    "    tic = time.perf_counter()\n",
    "    mixed_x, mixed_y, mixed_lam= gradmix_v2_improved_v2(input_sp.cuda(), targets.cuda(), grad.unsqueeze(1).cuda(), \n",
    "                                                 alpha = 0.5, normalization = 'standard', debug=False, \n",
    "                                                 rand_pos = 1.0)\n",
    "\n",
    "\n",
    "    toc = time.perf_counter()\n",
    "    total_time_list.append(toc-tic)\n",
    "#     update_time_list.append(total_time_in_update)\n",
    "#     update_counter_list.append(update_counter)\n",
    "# update_time_list = np.array(update_time_list)\n",
    "total_time_list= np.array(total_time_list)\n",
    "# update_counter_list=np.array(update_counter_list)\n",
    "print(f\"Average total time: {total_time_list.mean():0.4f} seconds (var: {total_time_list.var():0.4f})\")\n",
    "# print(f\"Average time on update: {update_time_list.mean():0.4f} seconds (var: {update_time_list.var():0.4f})\")\n",
    "# print(f\"Average update: {update_counter_list.mean():0.4f} times\")\n",
    "print(f\"Max/Min time: {total_time_list.max():0.4f}/{total_time_list.min():0.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average total time: 1.1706 seconds (var: 0.0001)\n",
      "Max/Min time: 1.1791/1.1535 seconds\n"
     ]
    }
   ],
   "source": [
    "total_time_list = []\n",
    "update_time_list = []\n",
    "update_counter_list = []\n",
    "for i in range(10):\n",
    "    tic = time.perf_counter()\n",
    "    mixed_x, mixed_y, mixed_lam= gradmix_v2_improved_v2(input_sp.cuda(), targets.cuda(), grad.unsqueeze(1).cuda(), \n",
    "                                                 alpha = 0.5, normalization = 'standard', debug=False, \n",
    "                                                 rand_pos = 1.0)\n",
    "\n",
    "\n",
    "    toc = time.perf_counter()\n",
    "    total_time_list.append(toc-tic)\n",
    "#     update_time_list.append(total_time_in_update)\n",
    "#     update_counter_list.append(update_counter)\n",
    "# update_time_list = np.array(update_time_list)\n",
    "total_time_list= np.array(total_time_list)\n",
    "# update_counter_list=np.array(update_counter_list)\n",
    "print(f\"Average total time: {total_time_list.mean():0.4f} seconds (var: {total_time_list.var():0.4f})\")\n",
    "# print(f\"Average time on update: {update_time_list.mean():0.4f} seconds (var: {update_time_list.var():0.4f})\")\n",
    "# print(f\"Average update: {update_counter_list.mean():0.4f} times\")\n",
    "print(f\"Max/Min time: {total_time_list.max():0.4f}/{total_time_list.min():0.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=32\n",
    "_x = np.linspace(1, 2*w-1, int(2*(w-1)))\n",
    "_y = np.linspace(1, 2*w-1, int(2*(w-1)))\n",
    "_xv, _yv = np.meshgrid(_x, _y)\n",
    "coord = np.stack((_xv.astype(int).flatten(), _yv.astype(int).flatten()))\n",
    "coord = coord[:,np.random.permutation(coord.shape[1])]\n",
    "# coord = coord[torch.randperm(coord.shape[1])]\n",
    "# print(coord.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3229,  525, 3530, ..., 1536,  635, 3495])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.permutation(coord.shape[1]).shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3844"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coord.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "od = OrderedDict()\n",
    "od['123'] = 123\n",
    "od['23dfad']= 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'123': 123, '23dfad': 14}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(od)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-env",
   "language": "python",
   "name": "new-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
