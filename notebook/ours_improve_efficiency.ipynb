{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd '/h/ama/workspace/ama-at-vector/best-mix'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "from mixup import mixup_graph\n",
    "import time\n",
    "from utils_mixup import gradmix_v2, gradmix_v2_improved\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_fig(input, target=None, title=None, save_dir=None):\n",
    "    fig, axes = plt.subplots(1,len(input),figsize=(3*len(input),3))\n",
    "    if title:\n",
    "        fig.suptitle(title, size=16)\n",
    "    if len(input) == 1 :\n",
    "        axes = [axes]\n",
    "        \n",
    "    for i, ax in enumerate(axes):\n",
    "        if len(input.shape) == 4:\n",
    "            ax.imshow(input[i].permute(1,2,0).numpy())\n",
    "        else :\n",
    "            ax.imshow(input[i].numpy(), cmap='gray', vmin=0., vmax=1.)\n",
    "        \n",
    "        if target is not None:\n",
    "            output = net((input[i].unsqueeze(0) - mean)/std)\n",
    "            loss = criterion(output, target[i:i+1])\n",
    "            ax.set_title(\"loss: {:.3f}\\n pred: {}\\n true : {}\".format(loss, CIFAR100_LABELS_LIST[output.max(1)[1][0]], CIFAR100_LABELS_LIST[target[i]]))\n",
    "        ax.axis('off')\n",
    "    plt.subplots_adjust(wspace = 0.1)\n",
    "    \n",
    "    if save_dir is not None:\n",
    "        plt.savefig(save_dir, bbox_inches = 'tight',  pad_inches = 0)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model, Data, Saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "''' Model '''\n",
    "import models\n",
    "# import torchvision.models as models\n",
    "from load_data import load_data_subset\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "resnet = models.__dict__['preactresnet18'](10, False, 1).cuda()\n",
    "\n",
    "# checkpoint = torch.load('/group-volume/Multimodal-Learning/ssl/vse_files/runs/fast_autoaugment/models/cifar10_preact_ckpt/vanilla.pth.tar')\n",
    "checkpoint = torch.load('checkpoint/cifar10_preact_ckpt_vanilla.pth.tar')\n",
    "\n",
    "od = OrderedDict()\n",
    "for key in checkpoint['state_dict'].keys():\n",
    "    od[key[7:]] = checkpoint['state_dict'][key]\n",
    "resnet.load_state_dict(od)\n",
    "\n",
    "# resnet = models.resnet18(pretrained=True)\n",
    "\n",
    "\n",
    "# resnet.load_state_dict(checkpoint['state_dict'])\n",
    "# mean = torch.tensor([x / 255 for x in [125.3, 123.0, 113.9]],dtype=torch.float32).reshape(1, 3, 1, 1).cuda()\n",
    "# std = torch.tensor([x / 255 for x in [63.0, 62.1, 66.7]], dtype=torch.float32).reshape(1, 3, 1, 1).cuda()\n",
    "labels_per_class = 5000\n",
    "mean = torch.tensor([125.3, 123.0, 113.9])/255\n",
    "std = torch.tensor([63.0, 62.1, 66.7])/255\n",
    "mean_torch = mean.unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "std_torch = std.unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "workers=2\n",
    "dataset='cifar10'\n",
    "# data_dir='/group-volume/Multimodal-Learning/ssl/vse_files/runs/fast_autoaugment/data'\n",
    "data_dir='data'\n",
    "valid_labels_per_class=0\n",
    "mixup_alpha=0\n",
    "train_loader, valid_loader, _, test_loader, num_classes = load_data_subset(batch_size,workers,dataset,data_dir,labels_per_class=labels_per_class,valid_labels_per_class=valid_labels_per_class,mixup_alpha=mixup_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Data '''\n",
    "\n",
    "sample_num=100\n",
    "for x,y in test_loader:\n",
    "    input_sp,targets = x[:sample_num,:],y[:sample_num]\n",
    "    break\n",
    "    \n",
    "# print_fig((input_sp * std_torch + mean_torch)[:sample_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Saliency '''\n",
    "resnet.cpu()\n",
    "resnet.eval()\n",
    "input_var = input_sp[:sample_num].clone().detach().requires_grad_(True)\n",
    "output = resnet(input_var)\n",
    "loss = criterion(output, targets[:sample_num])\n",
    "loss.backward()\n",
    "\n",
    "blurr = torchvision.transforms.GaussianBlur(5, sigma=(1.0, 1.0))\n",
    "grad = blurr(input_var.grad.detach().abs().mean(dim=1).squeeze())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average total time: 1.0593 seconds (var: 0.0008)\n",
      "Max/Min time: 1.1031/1.0076 seconds\n"
     ]
    }
   ],
   "source": [
    "total_time_list = []\n",
    "update_time_list = []\n",
    "update_counter_list = []\n",
    "for i in range(10):\n",
    "    tic = time.perf_counter()\n",
    "    mixed_x, mixed_y, mixed_lam= gradmix_v2(input_sp.cuda(), targets.cuda(), grad.unsqueeze(1).cuda(), \n",
    "                                                 alpha = 0.5, normalization = 'standard', stride = 1, debug=False, \n",
    "                                                 rand_pos = 0)\n",
    "\n",
    "\n",
    "    toc = time.perf_counter()\n",
    "    total_time_list.append(toc-tic)\n",
    "#     update_time_list.append(total_time_in_update)\n",
    "#     update_counter_list.append(update_counter)\n",
    "# update_time_list = np.array(update_time_list)\n",
    "total_time_list= np.array(total_time_list)\n",
    "# update_counter_list=np.array(update_counter_list)\n",
    "print(f\"Average total time: {total_time_list.mean():0.4f} seconds (var: {total_time_list.var():0.4f})\")\n",
    "# print(f\"Average time on update: {update_time_list.mean():0.4f} seconds (var: {update_time_list.var():0.4f})\")\n",
    "# print(f\"Average update: {update_counter_list.mean():0.4f} times\")\n",
    "print(f\"Max/Min time: {total_time_list.max():0.4f}/{total_time_list.min():0.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average total time: 0.6084 seconds (var: 0.0001)\n",
      "Max/Min time: 0.6223/0.5997 seconds\n"
     ]
    }
   ],
   "source": [
    "total_time_list = []\n",
    "update_time_list = []\n",
    "update_counter_list = []\n",
    "for i in range(10):\n",
    "    tic = time.perf_counter()\n",
    "    mixed_x, mixed_y, mixed_lam= gradmix_v2(input_sp.cuda(), targets.cuda(), grad.unsqueeze(1).cuda(), \n",
    "                                                 alpha = 0.5, normalization = 'standard', stride = 1, debug=False, \n",
    "                                                 rand_pos = 1)\n",
    "\n",
    "\n",
    "    toc = time.perf_counter()\n",
    "    total_time_list.append(toc-tic)\n",
    "#     update_time_list.append(total_time_in_update)\n",
    "#     update_counter_list.append(update_counter)\n",
    "# update_time_list = np.array(update_time_list)\n",
    "total_time_list= np.array(total_time_list)\n",
    "# update_counter_list=np.array(update_counter_list)\n",
    "print(f\"Average total time: {total_time_list.mean():0.4f} seconds (var: {total_time_list.var():0.4f})\")\n",
    "# print(f\"Average time on update: {update_time_list.mean():0.4f} seconds (var: {update_time_list.var():0.4f})\")\n",
    "# print(f\"Average update: {update_counter_list.mean():0.4f} times\")\n",
    "print(f\"Max/Min time: {total_time_list.max():0.4f}/{total_time_list.min():0.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average total time: 0.4760 seconds (var: 0.0002)\n",
      "Max/Min time: 0.4966/0.4433 seconds\n"
     ]
    }
   ],
   "source": [
    "total_time_list = []\n",
    "update_time_list = []\n",
    "update_counter_list = []\n",
    "for i in range(10):\n",
    "    tic = time.perf_counter()\n",
    "    mixed_x, mixed_y, mixed_lam= gradmix_v2_improved(input_sp.cuda(), targets.cuda(), grad.unsqueeze(1).cuda(), \n",
    "                                                 alpha = 0.5, normalization = 'standard', stride = 1, debug=False, \n",
    "                                                 rand_pos = 0)\n",
    "\n",
    "\n",
    "    toc = time.perf_counter()\n",
    "    total_time_list.append(toc-tic)\n",
    "#     update_time_list.append(total_time_in_update)\n",
    "#     update_counter_list.append(update_counter)\n",
    "# update_time_list = np.array(update_time_list)\n",
    "total_time_list= np.array(total_time_list)\n",
    "# update_counter_list=np.array(update_counter_list)\n",
    "print(f\"Average total time: {total_time_list.mean():0.4f} seconds (var: {total_time_list.var():0.4f})\")\n",
    "# print(f\"Average time on update: {update_time_list.mean():0.4f} seconds (var: {update_time_list.var():0.4f})\")\n",
    "# print(f\"Average update: {update_counter_list.mean():0.4f} times\")\n",
    "print(f\"Max/Min time: {total_time_list.max():0.4f}/{total_time_list.min():0.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average total time: 0.3696 seconds (var: 0.0001)\n",
      "Max/Min time: 0.3843/0.3586 seconds\n"
     ]
    }
   ],
   "source": [
    "total_time_list = []\n",
    "update_time_list = []\n",
    "update_counter_list = []\n",
    "for i in range(10):\n",
    "    tic = time.perf_counter()\n",
    "    mixed_x, mixed_y, mixed_lam= gradmix_v2_improved(input_sp.cuda(), targets.cuda(), grad.unsqueeze(1).cuda(), \n",
    "                                                 alpha = 0.5, normalization = 'standard', stride = 1, debug=False, \n",
    "                                                 rand_pos = 1)\n",
    "\n",
    "\n",
    "    toc = time.perf_counter()\n",
    "    total_time_list.append(toc-tic)\n",
    "#     update_time_list.append(total_time_in_update)\n",
    "#     update_counter_list.append(update_counter)\n",
    "# update_time_list = np.array(update_time_list)\n",
    "total_time_list= np.array(total_time_list)\n",
    "# update_counter_list=np.array(update_counter_list)\n",
    "print(f\"Average total time: {total_time_list.mean():0.4f} seconds (var: {total_time_list.var():0.4f})\")\n",
    "# print(f\"Average time on update: {update_time_list.mean():0.4f} seconds (var: {update_time_list.var():0.4f})\")\n",
    "# print(f\"Average update: {update_counter_list.mean():0.4f} times\")\n",
    "print(f\"Max/Min time: {total_time_list.max():0.4f}/{total_time_list.min():0.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-env",
   "language": "python",
   "name": "new-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
